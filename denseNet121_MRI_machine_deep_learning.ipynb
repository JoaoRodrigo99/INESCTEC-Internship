{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ6GUwzbRBCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdbcd14-05fe-499a-aa6f-3ff079941ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bYCLSrDMqx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f50a6b-4631-47d5-9fdd-47483df4422e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: monai in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: monai in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9->monai) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK\n",
        "!pip install monai\n",
        "!pip install --upgrade monai\n",
        "# !pip install torch-lr-finder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oSF0HCLRC-e"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "import monai\n",
        "from monai.networks.nets import DenseNet121\n",
        "from monai.metrics import ROCAUCMetric\n",
        "from monai.transforms import Compose, AddChannel, ScaleIntensity, ToTensor\n",
        "from monai.transforms import Spacing, create_grid\n",
        "from monai.transforms import RandRotate90, RandAdjustContrast, RandZoom, RandFlip, RandGaussianNoise, RandGibbsNoise, RandKSpaceSpikeNoise\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# from torch_lr_finder import LRFinder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "7C88zWnmnn1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CdaY2VmY-G9"
      },
      "outputs": [],
      "source": [
        "############################ DATASET ####################################\n",
        "\n",
        "class MRI_Dataset(Dataset):\n",
        "  def __init__(self, task, fold, modality, transforms):\n",
        "    self.task = task\n",
        "    self.fold = fold\n",
        "    self.modality = modality\n",
        "    self.transform=transforms\n",
        "    self.lib, self.target = pickle.load(open(\"/content/drive/My Drive/CTM/multimodal_glioma_data_multi_level.pickle\",\"rb\"))[fold][task]\n",
        "    self.data_path = pickle.load(open(f'/content/drive/My Drive/CTM/tabular_features_10_tiles/t1ce_flair/global/{task}_{fold}.pkl',\"rb\"))[0][\"path\"]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.target)\n",
        "\n",
        "  def targetTransform(self, target):\n",
        "\n",
        "    if(target['idh1'] == 0 and target['ioh1p19q'] == 0):\n",
        "      return 0\n",
        "    if(target['idh1'] == 1 and target['ioh1p19q'] == 0):\n",
        "      return 1\n",
        "    if(target['idh1'] == 1 and target['ioh1p19q'] == 1):\n",
        "      return 2\n",
        "\n",
        "  def __getitem__(self, patientID):\n",
        "    path = self.lib[patientID][self.modality]\n",
        "\n",
        "    map_dict = {'\\\\': '/'}\n",
        "    path = ''.join(idx if idx not in map_dict else map_dict[idx] for idx in path)\n",
        "    image_url = '/content/drive/My Drive/CTM/{}'.format(path)\n",
        "\n",
        "    pixels_array = np.load(image_url, allow_pickle=True)\n",
        "    pixels_array= self.transform(pixels_array)\n",
        "\n",
        "    return [pixels_array, self.data_path[patientID]], self.targetTransform(self.target[patientID])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXUBa9L2JzBr"
      },
      "outputs": [],
      "source": [
        "######################## TRANSFORMATIONS ########################\n",
        "\n",
        "train_transforms= Compose([ScaleIntensity(), RandRotate90(), RandAdjustContrast()])\n",
        "val_transforms= Compose([ScaleIntensity()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_test = MRI_Dataset('test', 4, 't1', val_transforms)\n",
        "\n",
        "# # t1ce + flair\n",
        "ds_train1 = MRI_Dataset('train', 4, 't1', train_transforms)\n",
        "ds_train2 = MRI_Dataset('train', 4, 't2', train_transforms)\n",
        "\n",
        "concat_dataset_train = ConcatDataset([ds_train1, ds_train2])\n",
        "\n",
        "train_dataloader = DataLoader(ds_train1, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_dataloader = DataLoader(ds_test, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "9tm-yAqokG0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearDenseNet121Head(nn.Module):\n",
        "    def __init__(self, spatial_dims, in_channels, out_channels, dropout_prob):\n",
        "        super(LinearDenseNet121Head, self).__init__()\n",
        "\n",
        "        self.model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=1024, pretrained=False, dropout_prob=dropout_prob).to(device)\n",
        "\n",
        "        #  Linear layer to replace AdaptiveAvgPool3d and ConvolutionalLayer\n",
        "        self.linear = nn.Sequential(#nn.Linear(512+5120,128),\n",
        "                                    nn.Linear(1024,128),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Dropout(dropout_prob),\n",
        "                                    nn.Linear(128,32),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Dropout(dropout_prob),\n",
        "                                    nn.Linear(32,out_channels))\n",
        "\n",
        "\n",
        "    def forward(self, x, data):\n",
        "        output_conv = self.model(x)\n",
        "        # pathData = data\n",
        "        # output = torch.cat((output, pathData), dim=1)\n",
        "        output = self.linear(output_conv)\n",
        "        return output_conv, output"
      ],
      "metadata": {
        "id": "ZaC9Wpgsao0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LinearDenseNet121Head(spatial_dims=3, in_channels=1, out_channels=3, dropout_prob=0.2).to(device)\n",
        "# model.head = LinearDenseNet121Head(spatial_dims=3, in_channels=128, out_channels=3, dropout_prob=1e-3)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "lr=1e-4\n",
        "weight_decay=1e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=weight_decay)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience = 5, threshold=0.01)\n",
        "max_epochs = 100"
      ],
      "metadata": {
        "id": "eq3rdpHOjl7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################### MODEL TRAIN\n",
        "\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "\n",
        "best_val_accuracy = 0.0\n",
        "best_model_weights = None\n",
        "\n",
        "epoch_loss_values = []\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"EPOCH {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    batch_iter = 0\n",
        "\n",
        "    print(\"Learning Rate= \", optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    for data, labels in train_dataloader:\n",
        "\n",
        "      if torch.cuda.is_available():\n",
        "        data[0], labels = data[0].cuda(), labels.cuda()\n",
        "        data[1] = data[1].cuda()\n",
        "\n",
        "      batch_iter += 1\n",
        "      optimizer.zero_grad()\n",
        "      _, outputs = model(torch.unsqueeze(data[0],1), data[1])\n",
        "      loss = loss_function(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "      # epoch_len = len(ds_train) // train_dataloader.batch_size\n",
        "\n",
        "    epoch_loss /= batch_iter\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(\"\")\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss}\")\n",
        "\n",
        "    scheduler.step(epoch_loss)\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    predicted_labels.clear()\n",
        "    true_labels.clear()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for data, labels in test_dataloader:\n",
        "          if torch.cuda.is_available():\n",
        "            data[0], labels = data[0].cuda(), labels.cuda()\n",
        "            data[1] = data[1].cuda()\n",
        "\n",
        "          _, outputs = model(torch.unsqueeze(data[0],1), data[1])\n",
        "          loss = loss_function(outputs, labels)\n",
        "          val_loss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "\n",
        "          predicted_labels.extend(predicted.cpu().numpy())\n",
        "          true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_accuracy = accuracy_score(true_labels, predicted_labels) * 100\n",
        "    val_loss /= len(test_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.4f}%\")\n",
        "\n",
        "\n",
        "    # weight freeze\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_model_weights = model.state_dict()\n",
        "        torch.save(best_model_weights, \"best_model_weights.pth\")\n",
        "\n",
        "print(\"\")\n",
        "print(\"-\" * 10)\n",
        "print(f\"BEST MODEL ACCURACY ->: {best_val_accuracy:.4f}%\")"
      ],
      "metadata": {
        "id": "TYzdxV94j31l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26b22c7-dc0f-4a32-8eef-b690026e3f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "EPOCH 1/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 1 average loss: 1.0501619338989259\n",
            "\n",
            "Validation Loss: 1.0476\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 2/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 2 average loss: 1.0202269792556762\n",
            "\n",
            "Validation Loss: 1.0049\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 3/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 3 average loss: 0.9863813519477844\n",
            "\n",
            "Validation Loss: 0.9705\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 4/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 4 average loss: 0.9623837828636169\n",
            "\n",
            "Validation Loss: 0.9483\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 5/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 5 average loss: 0.9459714889526367\n",
            "\n",
            "Validation Loss: 0.9380\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 6/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 6 average loss: 0.9210052371025086\n",
            "\n",
            "Validation Loss: 0.9350\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 7/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 7 average loss: 0.9515706896781921\n",
            "\n",
            "Validation Loss: 0.9409\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 8/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 8 average loss: 0.9287337183952331\n",
            "\n",
            "Validation Loss: 0.9420\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 9/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 9 average loss: 0.904895293712616\n",
            "\n",
            "Validation Loss: 0.9585\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 10/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 10 average loss: 0.8635905742645263\n",
            "\n",
            "Validation Loss: 0.9394\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 11/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 11 average loss: 0.849100649356842\n",
            "\n",
            "Validation Loss: 0.9203\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 12/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 12 average loss: 0.8484629392623901\n",
            "\n",
            "Validation Loss: 0.9791\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 13/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 13 average loss: 0.9005910396575928\n",
            "\n",
            "Validation Loss: 0.9861\n",
            "Validation Accuracy: 59.4595%\n",
            "----------\n",
            "EPOCH 14/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 14 average loss: 0.87051362991333\n",
            "\n",
            "Validation Loss: 0.9598\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 15/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 15 average loss: 0.8429855585098267\n",
            "\n",
            "Validation Loss: 1.0086\n",
            "Validation Accuracy: 43.2432%\n",
            "----------\n",
            "EPOCH 16/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 16 average loss: 0.8227371215820313\n",
            "\n",
            "Validation Loss: 1.0523\n",
            "Validation Accuracy: 32.4324%\n",
            "----------\n",
            "EPOCH 17/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 17 average loss: 0.8372565746307373\n",
            "\n",
            "Validation Loss: 1.0342\n",
            "Validation Accuracy: 32.4324%\n",
            "----------\n",
            "EPOCH 18/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 18 average loss: 0.8713515877723694\n",
            "\n",
            "Validation Loss: 1.0067\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 19/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 19 average loss: 0.8487380981445313\n",
            "\n",
            "Validation Loss: 1.0419\n",
            "Validation Accuracy: 35.1351%\n",
            "----------\n",
            "EPOCH 20/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 20 average loss: 0.7948802232742309\n",
            "\n",
            "Validation Loss: 1.0381\n",
            "Validation Accuracy: 32.4324%\n",
            "----------\n",
            "EPOCH 21/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 21 average loss: 0.7857195854187011\n",
            "\n",
            "Validation Loss: 1.0016\n",
            "Validation Accuracy: 32.4324%\n",
            "----------\n",
            "EPOCH 22/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 22 average loss: 0.7640870094299317\n",
            "\n",
            "Validation Loss: 0.9461\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 23/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 23 average loss: 0.8155516028404236\n",
            "\n",
            "Validation Loss: 1.1026\n",
            "Validation Accuracy: 29.7297%\n",
            "----------\n",
            "EPOCH 24/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 24 average loss: 0.7481361031532288\n",
            "\n",
            "Validation Loss: 1.1441\n",
            "Validation Accuracy: 29.7297%\n",
            "----------\n",
            "EPOCH 25/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 25 average loss: 0.699935793876648\n",
            "\n",
            "Validation Loss: 1.1478\n",
            "Validation Accuracy: 32.4324%\n",
            "----------\n",
            "EPOCH 26/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 26 average loss: 0.7740745782852173\n",
            "\n",
            "Validation Loss: 1.1544\n",
            "Validation Accuracy: 32.4324%\n",
            "----------\n",
            "EPOCH 27/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 27 average loss: 0.7291447877883911\n",
            "\n",
            "Validation Loss: 1.2262\n",
            "Validation Accuracy: 29.7297%\n",
            "----------\n",
            "EPOCH 28/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 28 average loss: 0.7345013856887818\n",
            "\n",
            "Validation Loss: 1.1013\n",
            "Validation Accuracy: 35.1351%\n",
            "----------\n",
            "EPOCH 29/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 29 average loss: 0.643415904045105\n",
            "\n",
            "Validation Loss: 1.1041\n",
            "Validation Accuracy: 37.8378%\n",
            "----------\n",
            "EPOCH 30/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 30 average loss: 0.682163941860199\n",
            "\n",
            "Validation Loss: 1.2629\n",
            "Validation Accuracy: 29.7297%\n",
            "----------\n",
            "EPOCH 31/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 31 average loss: 0.6254537105560303\n",
            "\n",
            "Validation Loss: 1.2852\n",
            "Validation Accuracy: 29.7297%\n",
            "----------\n",
            "EPOCH 32/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 32 average loss: 0.6109473824501037\n",
            "\n",
            "Validation Loss: 1.2466\n",
            "Validation Accuracy: 35.1351%\n",
            "----------\n",
            "EPOCH 33/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 33 average loss: 0.6684880971908569\n",
            "\n",
            "Validation Loss: 1.1916\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 34/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 34 average loss: 0.6788846135139466\n",
            "\n",
            "Validation Loss: 1.2348\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 35/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 35 average loss: 0.6807156205177307\n",
            "\n",
            "Validation Loss: 1.2506\n",
            "Validation Accuracy: 32.4324%\n",
            "----------\n",
            "EPOCH 36/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 36 average loss: 0.5967994689941406\n",
            "\n",
            "Validation Loss: 1.1506\n",
            "Validation Accuracy: 35.1351%\n",
            "----------\n",
            "EPOCH 37/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 37 average loss: 0.633849811553955\n",
            "\n",
            "Validation Loss: 1.0987\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 38/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 38 average loss: 0.619740879535675\n",
            "\n",
            "Validation Loss: 1.1060\n",
            "Validation Accuracy: 35.1351%\n",
            "----------\n",
            "EPOCH 39/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 39 average loss: 0.6227821588516236\n",
            "\n",
            "Validation Loss: 1.1806\n",
            "Validation Accuracy: 37.8378%\n",
            "----------\n",
            "EPOCH 40/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 40 average loss: 0.626278531551361\n",
            "\n",
            "Validation Loss: 1.0266\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 41/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 41 average loss: 0.6582064270973206\n",
            "\n",
            "Validation Loss: 0.9487\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 42/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 42 average loss: 0.5344657599925995\n",
            "\n",
            "Validation Loss: 0.8940\n",
            "Validation Accuracy: 59.4595%\n",
            "----------\n",
            "EPOCH 43/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 43 average loss: 0.5012434124946594\n",
            "\n",
            "Validation Loss: 0.9264\n",
            "Validation Accuracy: 56.7568%\n",
            "----------\n",
            "EPOCH 44/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 44 average loss: 0.5434324204921722\n",
            "\n",
            "Validation Loss: 1.1123\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 45/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 45 average loss: 0.5454495251178741\n",
            "\n",
            "Validation Loss: 1.1675\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 46/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 46 average loss: 0.5737074911594391\n",
            "\n",
            "Validation Loss: 1.1401\n",
            "Validation Accuracy: 43.2432%\n",
            "----------\n",
            "EPOCH 47/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 47 average loss: 0.5227786123752594\n",
            "\n",
            "Validation Loss: 1.0792\n",
            "Validation Accuracy: 54.0541%\n",
            "----------\n",
            "EPOCH 48/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 48 average loss: 0.5110886633396149\n",
            "\n",
            "Validation Loss: 1.0917\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 49/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 49 average loss: 0.480259382724762\n",
            "\n",
            "Validation Loss: 1.1048\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 50/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 50 average loss: 0.40361831784248353\n",
            "\n",
            "Validation Loss: 1.2490\n",
            "Validation Accuracy: 35.1351%\n",
            "----------\n",
            "EPOCH 51/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 51 average loss: 0.6326432824134827\n",
            "\n",
            "Validation Loss: 1.4003\n",
            "Validation Accuracy: 29.7297%\n",
            "----------\n",
            "EPOCH 52/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 52 average loss: 0.43839877247810366\n",
            "\n",
            "Validation Loss: 1.3805\n",
            "Validation Accuracy: 37.8378%\n",
            "----------\n",
            "EPOCH 53/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 53 average loss: 0.4096688747406006\n",
            "\n",
            "Validation Loss: 1.2521\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 54/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 54 average loss: 0.4496954381465912\n",
            "\n",
            "Validation Loss: 1.0749\n",
            "Validation Accuracy: 54.0541%\n",
            "----------\n",
            "EPOCH 55/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 55 average loss: 0.5290557622909546\n",
            "\n",
            "Validation Loss: 1.0383\n",
            "Validation Accuracy: 59.4595%\n",
            "----------\n",
            "EPOCH 56/100\n",
            "Learning Rate=  0.0001\n",
            "\n",
            "epoch 56 average loss: 0.4583573997020721\n",
            "\n",
            "Validation Loss: 1.2380\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 57/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 57 average loss: 0.5025322377681732\n",
            "\n",
            "Validation Loss: 1.2952\n",
            "Validation Accuracy: 43.2432%\n",
            "----------\n",
            "EPOCH 58/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 58 average loss: 0.44886347055435183\n",
            "\n",
            "Validation Loss: 1.3371\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 59/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 59 average loss: 0.3883134424686432\n",
            "\n",
            "Validation Loss: 1.3551\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 60/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 60 average loss: 0.3944419503211975\n",
            "\n",
            "Validation Loss: 1.3676\n",
            "Validation Accuracy: 40.5405%\n",
            "----------\n",
            "EPOCH 61/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 61 average loss: 0.46771950721740724\n",
            "\n",
            "Validation Loss: 1.3078\n",
            "Validation Accuracy: 43.2432%\n",
            "----------\n",
            "EPOCH 62/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 62 average loss: 0.4427564859390259\n",
            "\n",
            "Validation Loss: 1.2799\n",
            "Validation Accuracy: 43.2432%\n",
            "----------\n",
            "EPOCH 63/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 63 average loss: 0.4133753478527069\n",
            "\n",
            "Validation Loss: 1.2687\n",
            "Validation Accuracy: 43.2432%\n",
            "----------\n",
            "EPOCH 64/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 64 average loss: 0.3633806943893433\n",
            "\n",
            "Validation Loss: 1.2255\n",
            "Validation Accuracy: 45.9459%\n",
            "----------\n",
            "EPOCH 65/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 65 average loss: 0.3420325696468353\n",
            "\n",
            "Validation Loss: 1.2081\n",
            "Validation Accuracy: 45.9459%\n",
            "----------\n",
            "EPOCH 66/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 66 average loss: 0.3860481560230255\n",
            "\n",
            "Validation Loss: 1.2000\n",
            "Validation Accuracy: 45.9459%\n",
            "----------\n",
            "EPOCH 67/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 67 average loss: 0.5318261533975601\n",
            "\n",
            "Validation Loss: 1.1953\n",
            "Validation Accuracy: 45.9459%\n",
            "----------\n",
            "EPOCH 68/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 68 average loss: 0.39844892621040345\n",
            "\n",
            "Validation Loss: 1.2033\n",
            "Validation Accuracy: 45.9459%\n",
            "----------\n",
            "EPOCH 69/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 69 average loss: 0.3690157771110535\n",
            "\n",
            "Validation Loss: 1.2048\n",
            "Validation Accuracy: 45.9459%\n",
            "----------\n",
            "EPOCH 70/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 70 average loss: 0.3569664597511292\n",
            "\n",
            "Validation Loss: 1.1768\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 71/100\n",
            "Learning Rate=  1e-05\n",
            "\n",
            "epoch 71 average loss: 0.34539055824279785\n",
            "\n",
            "Validation Loss: 1.1926\n",
            "Validation Accuracy: 45.9459%\n",
            "----------\n",
            "EPOCH 72/100\n",
            "Learning Rate=  1.0000000000000002e-06\n",
            "\n",
            "epoch 72 average loss: 0.3805350214242935\n",
            "\n",
            "Validation Loss: 1.1685\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 73/100\n",
            "Learning Rate=  1.0000000000000002e-06\n",
            "\n",
            "epoch 73 average loss: 0.3622759521007538\n",
            "\n",
            "Validation Loss: 1.1479\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 74/100\n",
            "Learning Rate=  1.0000000000000002e-06\n",
            "\n",
            "epoch 74 average loss: 0.4124226331710815\n",
            "\n",
            "Validation Loss: 1.1768\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 75/100\n",
            "Learning Rate=  1.0000000000000002e-06\n",
            "\n",
            "epoch 75 average loss: 0.3624367117881775\n",
            "\n",
            "Validation Loss: 1.1782\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 76/100\n",
            "Learning Rate=  1.0000000000000002e-06\n",
            "\n",
            "epoch 76 average loss: 0.36412561535835264\n",
            "\n",
            "Validation Loss: 1.1723\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 77/100\n",
            "Learning Rate=  1.0000000000000002e-06\n",
            "\n",
            "epoch 77 average loss: 0.3690308392047882\n",
            "\n",
            "Validation Loss: 1.1575\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 78/100\n",
            "Learning Rate=  1.0000000000000002e-07\n",
            "\n",
            "epoch 78 average loss: 0.41283714175224306\n",
            "\n",
            "Validation Loss: 1.1459\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 79/100\n",
            "Learning Rate=  1.0000000000000002e-07\n",
            "\n",
            "epoch 79 average loss: 0.4239537060260773\n",
            "\n",
            "Validation Loss: 1.1481\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 80/100\n",
            "Learning Rate=  1.0000000000000002e-07\n",
            "\n",
            "epoch 80 average loss: 0.45371649861335756\n",
            "\n",
            "Validation Loss: 1.1807\n",
            "Validation Accuracy: 45.9459%\n",
            "----------\n",
            "EPOCH 81/100\n",
            "Learning Rate=  1.0000000000000002e-07\n",
            "\n",
            "epoch 81 average loss: 0.39577478766441343\n",
            "\n",
            "Validation Loss: 1.1525\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 82/100\n",
            "Learning Rate=  1.0000000000000002e-07\n",
            "\n",
            "epoch 82 average loss: 0.36509711742401124\n",
            "\n",
            "Validation Loss: 1.1333\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 83/100\n",
            "Learning Rate=  1.0000000000000002e-07\n",
            "\n",
            "epoch 83 average loss: 0.41174380779266356\n",
            "\n",
            "Validation Loss: 1.1458\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 84/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 84 average loss: 0.3700501322746277\n",
            "\n",
            "Validation Loss: 1.1323\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 85/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 85 average loss: 0.40897275805473327\n",
            "\n",
            "Validation Loss: 1.1566\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 86/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 86 average loss: 0.39477803111076354\n",
            "\n",
            "Validation Loss: 1.1576\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 87/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 87 average loss: 0.3272987425327301\n",
            "\n",
            "Validation Loss: 1.1474\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 88/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 88 average loss: 0.4423039317131042\n",
            "\n",
            "Validation Loss: 1.1486\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 89/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 89 average loss: 0.4120959103107452\n",
            "\n",
            "Validation Loss: 1.1535\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 90/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 90 average loss: 0.47431530952453616\n",
            "\n",
            "Validation Loss: 1.1300\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 91/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 91 average loss: 0.3928670883178711\n",
            "\n",
            "Validation Loss: 1.1127\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 92/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 92 average loss: 0.39484278559684755\n",
            "\n",
            "Validation Loss: 1.1800\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 93/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 93 average loss: 0.5085490345954895\n",
            "\n",
            "Validation Loss: 1.1692\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 94/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 94 average loss: 0.40909935235977174\n",
            "\n",
            "Validation Loss: 1.1444\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 95/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 95 average loss: 0.4820089340209961\n",
            "\n",
            "Validation Loss: 1.1378\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 96/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 96 average loss: 0.43881926536560056\n",
            "\n",
            "Validation Loss: 1.1573\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 97/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 97 average loss: 0.41361037492752073\n",
            "\n",
            "Validation Loss: 1.1558\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 98/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 98 average loss: 0.4813587129116058\n",
            "\n",
            "Validation Loss: 1.1409\n",
            "Validation Accuracy: 51.3514%\n",
            "----------\n",
            "EPOCH 99/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 99 average loss: 0.38405769467353823\n",
            "\n",
            "Validation Loss: 1.1716\n",
            "Validation Accuracy: 48.6486%\n",
            "----------\n",
            "EPOCH 100/100\n",
            "Learning Rate=  1.0000000000000004e-08\n",
            "\n",
            "epoch 100 average loss: 0.45958673357963564\n",
            "\n",
            "Validation Loss: 1.1712\n",
            "Validation Accuracy: 48.6486%\n",
            "\n",
            "----------\n",
            "BEST MODEL ACCURACY ->: 59.4595%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning"
      ],
      "metadata": {
        "id": "sV4gbTFRj4mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pAoAatp_IS4",
        "outputId": "21a3fa8d-1dd6-4dce-80c4-68c9f78e501b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, mean_absolute_error, auc, roc_curve, f1_score, make_scorer, roc_auc_score\n"
      ],
      "metadata": {
        "id": "OUXbOZtBcKtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeMetrics(y_test, y_pred, y_pred_prob, test_labels) :\n",
        "# Compute metrics - Accuracy, Mean Absolute Error, F1 Score, AUC\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    auc_score = roc_auc_score(test_labels, y_pred_prob, average='weighted', multi_class='ovr')\n",
        "\n",
        "    print('Accuracy:', round(accuracy,6)*100)\n",
        "    print('Mean Absolute Error:', round(mae,3))\n",
        "    print('F1 Score:',  round(f1,6)*100)\n",
        "    print('AUC:', round(auc_score,3))\n",
        "\n",
        "    print(\"Confusion Matrix : \\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "_nrYvAlgefrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold = 4\n",
        "multi = False\n",
        "\n",
        "ds_test = MRI_Dataset('test', fold, 't1', val_transforms)\n",
        "\n",
        "ds_train = MRI_Dataset('train', fold, 't1', train_transforms)\n",
        "ds_train2 = MRI_Dataset('train', fold, 't2', train_transforms)\n",
        "concat_dataset_train = ConcatDataset([ds_train, ds_train2])\n",
        "\n",
        "\n",
        "if(multi):\n",
        "  ds_train = concat_dataset_train\n",
        "\n",
        "train_dataloader = DataLoader(ds_train, batch_size=1, shuffle=True, num_workers=2)\n",
        "test_dataloader = DataLoader(ds_test, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "ml_feat_mri_train = []\n",
        "ml_feat_path_train = []\n",
        "ml_labels_train = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "      for data, labels in train_dataloader:\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          data[0], labels = data[0].cuda(), labels.cuda()\n",
        "          data[1] = data[1].cuda()\n",
        "\n",
        "        ml_feat_path_train.append(torch.squeeze(data[1].cpu()).numpy())\n",
        "\n",
        "        feature_vector, output = model(torch.unsqueeze(data[0],1), data[1])\n",
        "        ml_feat_mri_train.append(torch.squeeze(feature_vector.cpu()).numpy())\n",
        "        ml_labels_train.append(labels.cpu().numpy())\n",
        "\n",
        "ml_feat_mri_test = []\n",
        "ml_feat_path_test = []\n",
        "ml_labels_test = []\n",
        "with torch.no_grad():\n",
        "      for data, labels in test_dataloader:\n",
        "        # gc.collect()\n",
        "        # torch.cuda.empty_cache()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          data[0], labels = data[0].cuda(), labels.cuda()\n",
        "          data[1] = data[1].cuda()\n",
        "\n",
        "        ml_feat_path_test.append(torch.squeeze(data[1].cpu()).numpy())\n",
        "\n",
        "        feature_vector, output = model(torch.unsqueeze(data[0],1), data[1])\n",
        "        ml_feat_mri_test.append(torch.squeeze(feature_vector.cpu()).numpy())\n",
        "        ml_labels_test.append(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "gxN_NAB3sRXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getMetricsForClassfier(classifier):\n",
        "\n",
        "  classifier.fit(ml_feat_mri_train, np.ravel(ml_labels_train)) # using np.ravel to fix data conversion warning\n",
        "\n",
        "  y_pred = classifier.predict(ml_feat_mri_test)\n",
        "\n",
        "  y_pred_prob = classifier.predict_proba(ml_feat_mri_test)\n",
        "  computeMetrics(ml_labels_test, y_pred, y_pred_prob, ml_labels_test)"
      ],
      "metadata": {
        "id": "zuqM1bSraEJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LR"
      ],
      "metadata": {
        "id": "pWqzO9xRnUby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# params = {'C': 1.0, 'max_iter': 800, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'saga'}\n",
        "\n",
        "# lr_clf = LogisticRegression(**params)\n",
        "\n",
        "\n",
        "# getMetricsForClassfier(lr_clf)"
      ],
      "metadata": {
        "id": "2uNhVUKIbEf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##KNN"
      ],
      "metadata": {
        "id": "LZ2Ibu9wnWaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# knn_clf=KNeighborsClassifier(n_neighbors = 8)\n",
        "\n",
        "# getMetricsForClassfier(knn_clf, 0, False)"
      ],
      "metadata": {
        "id": "MNR_badDlxN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RF"
      ],
      "metadata": {
        "id": "jSf4PRSdnXwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# params = {'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 8, 'n_estimators': 200}\n",
        "\n",
        "# rf_clf = RandomForestClassifier(**params)\n",
        "\n",
        "# getMetricsForClassfier(rf_clf, 0, False)"
      ],
      "metadata": {
        "id": "GTOSsXepl9gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVC"
      ],
      "metadata": {
        "id": "YFaizmg_nZRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# params = {'C': 1, 'gamma': 0.1, 'kernel': 'linear', 'probability': True}\n",
        "\n",
        "\n",
        "# svc_clf = SVC(**params)\n",
        "\n",
        "# getMetricsForClassfier(svc_clf, 0, False)"
      ],
      "metadata": {
        "id": "HNeh355qmjwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGB"
      ],
      "metadata": {
        "id": "Pcz7XodjnbvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgb_clf=XGBClassifier(colsample_bytree= 0.6, gamma= 3, max_depth= 5, min_child_weight= 1, predictor= 'gpu_predictor', subsample= 0.8)\n",
        "\n",
        "# getMetricsForClassfier(xgb_clf, 0, False)"
      ],
      "metadata": {
        "id": "ceNoTCy1m7Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CAT"
      ],
      "metadata": {
        "id": "18dAJeWEnc2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_clf = CatBoostClassifier(bagging_temperature= 10,boosting_type= 'Plain', depth= 4,\n",
        "                          iterations= 500, l2_leaf_reg= 1, leaf_estimation_iterations= 1,\n",
        "                          learning_rate= 0.05, silent= False, task_type= 'GPU',loss_function='MultiClass' )\n",
        "\n",
        "getMetricsForClassfier(cat_clf)"
      ],
      "metadata": {
        "id": "4GA2H3bomyvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea4097f-2454-47ff-ac98-f09c1a5d92ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% gpu memory available for training. Free: 572.8125 Total: 15101.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.0416803\ttotal: 33.8ms\tremaining: 16.9s\n",
            "1:\tlearn: 0.9863330\ttotal: 66.2ms\tremaining: 16.5s\n",
            "2:\tlearn: 0.9341041\ttotal: 97.3ms\tremaining: 16.1s\n",
            "3:\tlearn: 0.8843665\ttotal: 127ms\tremaining: 15.7s\n",
            "4:\tlearn: 0.8403735\ttotal: 158ms\tremaining: 15.6s\n",
            "5:\tlearn: 0.8050842\ttotal: 189ms\tremaining: 15.6s\n",
            "6:\tlearn: 0.7691502\ttotal: 213ms\tremaining: 15s\n",
            "7:\tlearn: 0.7375887\ttotal: 271ms\tremaining: 16.7s\n",
            "8:\tlearn: 0.7079518\ttotal: 310ms\tremaining: 16.9s\n",
            "9:\tlearn: 0.6812886\ttotal: 333ms\tremaining: 16.3s\n",
            "10:\tlearn: 0.6582684\ttotal: 360ms\tremaining: 16s\n",
            "11:\tlearn: 0.6347606\ttotal: 393ms\tremaining: 16s\n",
            "12:\tlearn: 0.6134054\ttotal: 426ms\tremaining: 16s\n",
            "13:\tlearn: 0.5951540\ttotal: 456ms\tremaining: 15.8s\n",
            "14:\tlearn: 0.5769996\ttotal: 491ms\tremaining: 15.9s\n",
            "15:\tlearn: 0.5573888\ttotal: 525ms\tremaining: 15.9s\n",
            "16:\tlearn: 0.5436023\ttotal: 559ms\tremaining: 15.9s\n",
            "17:\tlearn: 0.5309160\ttotal: 593ms\tremaining: 15.9s\n",
            "18:\tlearn: 0.5175703\ttotal: 626ms\tremaining: 15.9s\n",
            "19:\tlearn: 0.5028592\ttotal: 644ms\tremaining: 15.4s\n",
            "20:\tlearn: 0.4891425\ttotal: 652ms\tremaining: 14.9s\n",
            "21:\tlearn: 0.4765706\ttotal: 661ms\tremaining: 14.4s\n",
            "22:\tlearn: 0.4649586\ttotal: 670ms\tremaining: 13.9s\n",
            "23:\tlearn: 0.4538737\ttotal: 678ms\tremaining: 13.5s\n",
            "24:\tlearn: 0.4408254\ttotal: 687ms\tremaining: 13s\n",
            "25:\tlearn: 0.4298548\ttotal: 699ms\tremaining: 12.7s\n",
            "26:\tlearn: 0.4208294\ttotal: 708ms\tremaining: 12.4s\n",
            "27:\tlearn: 0.4132516\ttotal: 718ms\tremaining: 12.1s\n",
            "28:\tlearn: 0.4033087\ttotal: 726ms\tremaining: 11.8s\n",
            "29:\tlearn: 0.3964013\ttotal: 734ms\tremaining: 11.5s\n",
            "30:\tlearn: 0.3893586\ttotal: 747ms\tremaining: 11.3s\n",
            "31:\tlearn: 0.3818259\ttotal: 766ms\tremaining: 11.2s\n",
            "32:\tlearn: 0.3733629\ttotal: 779ms\tremaining: 11s\n",
            "33:\tlearn: 0.3661829\ttotal: 798ms\tremaining: 10.9s\n",
            "34:\tlearn: 0.3613195\ttotal: 809ms\tremaining: 10.7s\n",
            "35:\tlearn: 0.3537192\ttotal: 816ms\tremaining: 10.5s\n",
            "36:\tlearn: 0.3466157\ttotal: 824ms\tremaining: 10.3s\n",
            "37:\tlearn: 0.3398265\ttotal: 831ms\tremaining: 10.1s\n",
            "38:\tlearn: 0.3325934\ttotal: 839ms\tremaining: 9.92s\n",
            "39:\tlearn: 0.3256888\ttotal: 848ms\tremaining: 9.75s\n",
            "40:\tlearn: 0.3208347\ttotal: 857ms\tremaining: 9.59s\n",
            "41:\tlearn: 0.3158662\ttotal: 865ms\tremaining: 9.43s\n",
            "42:\tlearn: 0.3117146\ttotal: 874ms\tremaining: 9.29s\n",
            "43:\tlearn: 0.3072193\ttotal: 882ms\tremaining: 9.14s\n",
            "44:\tlearn: 0.3020829\ttotal: 891ms\tremaining: 9.01s\n",
            "45:\tlearn: 0.2975836\ttotal: 903ms\tremaining: 8.91s\n",
            "46:\tlearn: 0.2921702\ttotal: 910ms\tremaining: 8.77s\n",
            "47:\tlearn: 0.2882432\ttotal: 918ms\tremaining: 8.64s\n",
            "48:\tlearn: 0.2844751\ttotal: 925ms\tremaining: 8.52s\n",
            "49:\tlearn: 0.2792417\ttotal: 933ms\tremaining: 8.39s\n",
            "50:\tlearn: 0.2741163\ttotal: 940ms\tremaining: 8.28s\n",
            "51:\tlearn: 0.2698814\ttotal: 948ms\tremaining: 8.17s\n",
            "52:\tlearn: 0.2668040\ttotal: 958ms\tremaining: 8.08s\n",
            "53:\tlearn: 0.2636479\ttotal: 966ms\tremaining: 7.98s\n",
            "54:\tlearn: 0.2611454\ttotal: 974ms\tremaining: 7.88s\n",
            "55:\tlearn: 0.2574617\ttotal: 981ms\tremaining: 7.78s\n",
            "56:\tlearn: 0.2552677\ttotal: 990ms\tremaining: 7.7s\n",
            "57:\tlearn: 0.2527729\ttotal: 997ms\tremaining: 7.6s\n",
            "58:\tlearn: 0.2498399\ttotal: 1s\tremaining: 7.51s\n",
            "59:\tlearn: 0.2465652\ttotal: 1.01s\tremaining: 7.41s\n",
            "60:\tlearn: 0.2435391\ttotal: 1.02s\tremaining: 7.36s\n",
            "61:\tlearn: 0.2408655\ttotal: 1.03s\tremaining: 7.27s\n",
            "62:\tlearn: 0.2386936\ttotal: 1.04s\tremaining: 7.2s\n",
            "63:\tlearn: 0.2351962\ttotal: 1.05s\tremaining: 7.19s\n",
            "64:\tlearn: 0.2315746\ttotal: 1.06s\tremaining: 7.1s\n",
            "65:\tlearn: 0.2295645\ttotal: 1.07s\tremaining: 7.02s\n",
            "66:\tlearn: 0.2257943\ttotal: 1.07s\tremaining: 6.94s\n",
            "67:\tlearn: 0.2230463\ttotal: 1.08s\tremaining: 6.86s\n",
            "68:\tlearn: 0.2201349\ttotal: 1.09s\tremaining: 6.79s\n",
            "69:\tlearn: 0.2168336\ttotal: 1.09s\tremaining: 6.72s\n",
            "70:\tlearn: 0.2148837\ttotal: 1.1s\tremaining: 6.67s\n",
            "71:\tlearn: 0.2117970\ttotal: 1.11s\tremaining: 6.6s\n",
            "72:\tlearn: 0.2096304\ttotal: 1.12s\tremaining: 6.53s\n",
            "73:\tlearn: 0.2076827\ttotal: 1.12s\tremaining: 6.47s\n",
            "74:\tlearn: 0.2056456\ttotal: 1.13s\tremaining: 6.4s\n",
            "75:\tlearn: 0.2031909\ttotal: 1.14s\tremaining: 6.34s\n",
            "76:\tlearn: 0.2013977\ttotal: 1.14s\tremaining: 6.28s\n",
            "77:\tlearn: 0.1995357\ttotal: 1.15s\tremaining: 6.22s\n",
            "78:\tlearn: 0.1978254\ttotal: 1.16s\tremaining: 6.16s\n",
            "79:\tlearn: 0.1950721\ttotal: 1.16s\tremaining: 6.1s\n",
            "80:\tlearn: 0.1930957\ttotal: 1.17s\tremaining: 6.04s\n",
            "81:\tlearn: 0.1899118\ttotal: 1.17s\tremaining: 5.99s\n",
            "82:\tlearn: 0.1882200\ttotal: 1.18s\tremaining: 5.93s\n",
            "83:\tlearn: 0.1869494\ttotal: 1.19s\tremaining: 5.88s\n",
            "84:\tlearn: 0.1852521\ttotal: 1.19s\tremaining: 5.83s\n",
            "85:\tlearn: 0.1835562\ttotal: 1.2s\tremaining: 5.78s\n",
            "86:\tlearn: 0.1809038\ttotal: 1.21s\tremaining: 5.73s\n",
            "87:\tlearn: 0.1793220\ttotal: 1.21s\tremaining: 5.68s\n",
            "88:\tlearn: 0.1780804\ttotal: 1.22s\tremaining: 5.63s\n",
            "89:\tlearn: 0.1771524\ttotal: 1.23s\tremaining: 5.59s\n",
            "90:\tlearn: 0.1753291\ttotal: 1.23s\tremaining: 5.54s\n",
            "91:\tlearn: 0.1739511\ttotal: 1.24s\tremaining: 5.5s\n",
            "92:\tlearn: 0.1722351\ttotal: 1.25s\tremaining: 5.45s\n",
            "93:\tlearn: 0.1697983\ttotal: 1.25s\tremaining: 5.41s\n",
            "94:\tlearn: 0.1681345\ttotal: 1.26s\tremaining: 5.37s\n",
            "95:\tlearn: 0.1668884\ttotal: 1.26s\tremaining: 5.33s\n",
            "96:\tlearn: 0.1650724\ttotal: 1.27s\tremaining: 5.28s\n",
            "97:\tlearn: 0.1629926\ttotal: 1.28s\tremaining: 5.24s\n",
            "98:\tlearn: 0.1616313\ttotal: 1.28s\tremaining: 5.2s\n",
            "99:\tlearn: 0.1604332\ttotal: 1.29s\tremaining: 5.16s\n",
            "100:\tlearn: 0.1591691\ttotal: 1.32s\tremaining: 5.22s\n",
            "101:\tlearn: 0.1582268\ttotal: 1.33s\tremaining: 5.2s\n",
            "102:\tlearn: 0.1564892\ttotal: 1.36s\tremaining: 5.23s\n",
            "103:\tlearn: 0.1544417\ttotal: 1.39s\tremaining: 5.29s\n",
            "104:\tlearn: 0.1535718\ttotal: 1.4s\tremaining: 5.25s\n",
            "105:\tlearn: 0.1523893\ttotal: 1.41s\tremaining: 5.24s\n",
            "106:\tlearn: 0.1507637\ttotal: 1.42s\tremaining: 5.21s\n",
            "107:\tlearn: 0.1497330\ttotal: 1.43s\tremaining: 5.18s\n",
            "108:\tlearn: 0.1486187\ttotal: 1.43s\tremaining: 5.14s\n",
            "109:\tlearn: 0.1474851\ttotal: 1.44s\tremaining: 5.12s\n",
            "110:\tlearn: 0.1463786\ttotal: 1.45s\tremaining: 5.1s\n",
            "111:\tlearn: 0.1454167\ttotal: 1.47s\tremaining: 5.08s\n",
            "112:\tlearn: 0.1444269\ttotal: 1.48s\tremaining: 5.06s\n",
            "113:\tlearn: 0.1435178\ttotal: 1.49s\tremaining: 5.03s\n",
            "114:\tlearn: 0.1425639\ttotal: 1.5s\tremaining: 5.01s\n",
            "115:\tlearn: 0.1412987\ttotal: 1.51s\tremaining: 4.99s\n",
            "116:\tlearn: 0.1404698\ttotal: 1.53s\tremaining: 5s\n",
            "117:\tlearn: 0.1397519\ttotal: 1.55s\tremaining: 5s\n",
            "118:\tlearn: 0.1386209\ttotal: 1.57s\tremaining: 5.04s\n",
            "119:\tlearn: 0.1379773\ttotal: 1.6s\tremaining: 5.07s\n",
            "120:\tlearn: 0.1369080\ttotal: 1.64s\tremaining: 5.14s\n",
            "121:\tlearn: 0.1353428\ttotal: 1.66s\tremaining: 5.14s\n",
            "122:\tlearn: 0.1343650\ttotal: 1.67s\tremaining: 5.11s\n",
            "123:\tlearn: 0.1336131\ttotal: 1.67s\tremaining: 5.07s\n",
            "124:\tlearn: 0.1322309\ttotal: 1.68s\tremaining: 5.04s\n",
            "125:\tlearn: 0.1313874\ttotal: 1.69s\tremaining: 5s\n",
            "126:\tlearn: 0.1301748\ttotal: 1.69s\tremaining: 4.97s\n",
            "127:\tlearn: 0.1297676\ttotal: 1.7s\tremaining: 4.93s\n",
            "128:\tlearn: 0.1289159\ttotal: 1.7s\tremaining: 4.9s\n",
            "129:\tlearn: 0.1283839\ttotal: 1.71s\tremaining: 4.87s\n",
            "130:\tlearn: 0.1273137\ttotal: 1.72s\tremaining: 4.84s\n",
            "131:\tlearn: 0.1262134\ttotal: 1.73s\tremaining: 4.81s\n",
            "132:\tlearn: 0.1249353\ttotal: 1.74s\tremaining: 4.79s\n",
            "133:\tlearn: 0.1238496\ttotal: 1.76s\tremaining: 4.8s\n",
            "134:\tlearn: 0.1230514\ttotal: 1.76s\tremaining: 4.77s\n",
            "135:\tlearn: 0.1220687\ttotal: 1.78s\tremaining: 4.76s\n",
            "136:\tlearn: 0.1208512\ttotal: 1.79s\tremaining: 4.75s\n",
            "137:\tlearn: 0.1198942\ttotal: 1.8s\tremaining: 4.73s\n",
            "138:\tlearn: 0.1187693\ttotal: 1.81s\tremaining: 4.7s\n",
            "139:\tlearn: 0.1179757\ttotal: 1.82s\tremaining: 4.67s\n",
            "140:\tlearn: 0.1171040\ttotal: 1.82s\tremaining: 4.64s\n",
            "141:\tlearn: 0.1163548\ttotal: 1.83s\tremaining: 4.61s\n",
            "142:\tlearn: 0.1152434\ttotal: 1.84s\tremaining: 4.58s\n",
            "143:\tlearn: 0.1146765\ttotal: 1.84s\tremaining: 4.56s\n",
            "144:\tlearn: 0.1136612\ttotal: 1.85s\tremaining: 4.53s\n",
            "145:\tlearn: 0.1131439\ttotal: 1.85s\tremaining: 4.5s\n",
            "146:\tlearn: 0.1121991\ttotal: 1.86s\tremaining: 4.47s\n",
            "147:\tlearn: 0.1115660\ttotal: 1.87s\tremaining: 4.44s\n",
            "148:\tlearn: 0.1105886\ttotal: 1.87s\tremaining: 4.41s\n",
            "149:\tlearn: 0.1098384\ttotal: 1.88s\tremaining: 4.39s\n",
            "150:\tlearn: 0.1094585\ttotal: 1.89s\tremaining: 4.36s\n",
            "151:\tlearn: 0.1090618\ttotal: 1.89s\tremaining: 4.33s\n",
            "152:\tlearn: 0.1078704\ttotal: 1.9s\tremaining: 4.3s\n",
            "153:\tlearn: 0.1069359\ttotal: 1.9s\tremaining: 4.28s\n",
            "154:\tlearn: 0.1063096\ttotal: 1.91s\tremaining: 4.25s\n",
            "155:\tlearn: 0.1055676\ttotal: 1.92s\tremaining: 4.23s\n",
            "156:\tlearn: 0.1047087\ttotal: 1.93s\tremaining: 4.22s\n",
            "157:\tlearn: 0.1039193\ttotal: 1.94s\tremaining: 4.2s\n",
            "158:\tlearn: 0.1035115\ttotal: 1.95s\tremaining: 4.17s\n",
            "159:\tlearn: 0.1029937\ttotal: 1.95s\tremaining: 4.15s\n",
            "160:\tlearn: 0.1021840\ttotal: 1.96s\tremaining: 4.12s\n",
            "161:\tlearn: 0.1017820\ttotal: 1.96s\tremaining: 4.1s\n",
            "162:\tlearn: 0.1014848\ttotal: 1.97s\tremaining: 4.08s\n",
            "163:\tlearn: 0.1009129\ttotal: 1.98s\tremaining: 4.05s\n",
            "164:\tlearn: 0.1002545\ttotal: 1.98s\tremaining: 4.03s\n",
            "165:\tlearn: 0.0997432\ttotal: 1.99s\tremaining: 4s\n",
            "166:\tlearn: 0.0988024\ttotal: 2s\tremaining: 3.98s\n",
            "167:\tlearn: 0.0980354\ttotal: 2s\tremaining: 3.96s\n",
            "168:\tlearn: 0.0969330\ttotal: 2.01s\tremaining: 3.94s\n",
            "169:\tlearn: 0.0962737\ttotal: 2.02s\tremaining: 3.91s\n",
            "170:\tlearn: 0.0958612\ttotal: 2.02s\tremaining: 3.89s\n",
            "171:\tlearn: 0.0955085\ttotal: 2.03s\tremaining: 3.87s\n",
            "172:\tlearn: 0.0950162\ttotal: 2.04s\tremaining: 3.86s\n",
            "173:\tlearn: 0.0942867\ttotal: 2.05s\tremaining: 3.84s\n",
            "174:\tlearn: 0.0937358\ttotal: 2.06s\tremaining: 3.82s\n",
            "175:\tlearn: 0.0930243\ttotal: 2.06s\tremaining: 3.79s\n",
            "176:\tlearn: 0.0926335\ttotal: 2.07s\tremaining: 3.77s\n",
            "177:\tlearn: 0.0921749\ttotal: 2.07s\tremaining: 3.75s\n",
            "178:\tlearn: 0.0915488\ttotal: 2.08s\tremaining: 3.73s\n",
            "179:\tlearn: 0.0910532\ttotal: 2.09s\tremaining: 3.71s\n",
            "180:\tlearn: 0.0904054\ttotal: 2.09s\tremaining: 3.69s\n",
            "181:\tlearn: 0.0897395\ttotal: 2.1s\tremaining: 3.67s\n",
            "182:\tlearn: 0.0888109\ttotal: 2.11s\tremaining: 3.65s\n",
            "183:\tlearn: 0.0882704\ttotal: 2.11s\tremaining: 3.63s\n",
            "184:\tlearn: 0.0879529\ttotal: 2.12s\tremaining: 3.61s\n",
            "185:\tlearn: 0.0875418\ttotal: 2.13s\tremaining: 3.6s\n",
            "186:\tlearn: 0.0870839\ttotal: 2.14s\tremaining: 3.58s\n",
            "187:\tlearn: 0.0865946\ttotal: 2.14s\tremaining: 3.56s\n",
            "188:\tlearn: 0.0861329\ttotal: 2.15s\tremaining: 3.54s\n",
            "189:\tlearn: 0.0858230\ttotal: 2.16s\tremaining: 3.52s\n",
            "190:\tlearn: 0.0852368\ttotal: 2.17s\tremaining: 3.51s\n",
            "191:\tlearn: 0.0847845\ttotal: 2.17s\tremaining: 3.49s\n",
            "192:\tlearn: 0.0843561\ttotal: 2.18s\tremaining: 3.47s\n",
            "193:\tlearn: 0.0839775\ttotal: 2.19s\tremaining: 3.45s\n",
            "194:\tlearn: 0.0833549\ttotal: 2.19s\tremaining: 3.43s\n",
            "195:\tlearn: 0.0829971\ttotal: 2.2s\tremaining: 3.42s\n",
            "196:\tlearn: 0.0824995\ttotal: 2.21s\tremaining: 3.4s\n",
            "197:\tlearn: 0.0822236\ttotal: 2.21s\tremaining: 3.38s\n",
            "198:\tlearn: 0.0819583\ttotal: 2.22s\tremaining: 3.36s\n",
            "199:\tlearn: 0.0817489\ttotal: 2.23s\tremaining: 3.34s\n",
            "200:\tlearn: 0.0811434\ttotal: 2.23s\tremaining: 3.32s\n",
            "201:\tlearn: 0.0808564\ttotal: 2.24s\tremaining: 3.31s\n",
            "202:\tlearn: 0.0802271\ttotal: 2.25s\tremaining: 3.29s\n",
            "203:\tlearn: 0.0797612\ttotal: 2.25s\tremaining: 3.27s\n",
            "204:\tlearn: 0.0791987\ttotal: 2.26s\tremaining: 3.25s\n",
            "205:\tlearn: 0.0785973\ttotal: 2.27s\tremaining: 3.23s\n",
            "206:\tlearn: 0.0783600\ttotal: 2.27s\tremaining: 3.22s\n",
            "207:\tlearn: 0.0779159\ttotal: 2.28s\tremaining: 3.2s\n",
            "208:\tlearn: 0.0774218\ttotal: 2.29s\tremaining: 3.18s\n",
            "209:\tlearn: 0.0770663\ttotal: 2.29s\tremaining: 3.17s\n",
            "210:\tlearn: 0.0765774\ttotal: 2.3s\tremaining: 3.15s\n",
            "211:\tlearn: 0.0761988\ttotal: 2.31s\tremaining: 3.13s\n",
            "212:\tlearn: 0.0759449\ttotal: 2.31s\tremaining: 3.12s\n",
            "213:\tlearn: 0.0756223\ttotal: 2.32s\tremaining: 3.1s\n",
            "214:\tlearn: 0.0753106\ttotal: 2.33s\tremaining: 3.09s\n",
            "215:\tlearn: 0.0750234\ttotal: 2.34s\tremaining: 3.07s\n",
            "216:\tlearn: 0.0746853\ttotal: 2.34s\tremaining: 3.05s\n",
            "217:\tlearn: 0.0742611\ttotal: 2.35s\tremaining: 3.04s\n",
            "218:\tlearn: 0.0738737\ttotal: 2.35s\tremaining: 3.02s\n",
            "219:\tlearn: 0.0734322\ttotal: 2.36s\tremaining: 3s\n",
            "220:\tlearn: 0.0730302\ttotal: 2.37s\tremaining: 2.99s\n",
            "221:\tlearn: 0.0728223\ttotal: 2.37s\tremaining: 2.97s\n",
            "222:\tlearn: 0.0724383\ttotal: 2.38s\tremaining: 2.96s\n",
            "223:\tlearn: 0.0720204\ttotal: 2.39s\tremaining: 2.94s\n",
            "224:\tlearn: 0.0718300\ttotal: 2.39s\tremaining: 2.93s\n",
            "225:\tlearn: 0.0714484\ttotal: 2.4s\tremaining: 2.91s\n",
            "226:\tlearn: 0.0710874\ttotal: 2.41s\tremaining: 2.89s\n",
            "227:\tlearn: 0.0707008\ttotal: 2.41s\tremaining: 2.88s\n",
            "228:\tlearn: 0.0705585\ttotal: 2.42s\tremaining: 2.86s\n",
            "229:\tlearn: 0.0702677\ttotal: 2.43s\tremaining: 2.85s\n",
            "230:\tlearn: 0.0699333\ttotal: 2.43s\tremaining: 2.83s\n",
            "231:\tlearn: 0.0695764\ttotal: 2.44s\tremaining: 2.82s\n",
            "232:\tlearn: 0.0692972\ttotal: 2.44s\tremaining: 2.8s\n",
            "233:\tlearn: 0.0690775\ttotal: 2.47s\tremaining: 2.81s\n",
            "234:\tlearn: 0.0686808\ttotal: 2.49s\tremaining: 2.8s\n",
            "235:\tlearn: 0.0682360\ttotal: 2.49s\tremaining: 2.79s\n",
            "236:\tlearn: 0.0678099\ttotal: 2.5s\tremaining: 2.77s\n",
            "237:\tlearn: 0.0675992\ttotal: 2.5s\tremaining: 2.76s\n",
            "238:\tlearn: 0.0671369\ttotal: 2.51s\tremaining: 2.74s\n",
            "239:\tlearn: 0.0667561\ttotal: 2.52s\tremaining: 2.73s\n",
            "240:\tlearn: 0.0665896\ttotal: 2.53s\tremaining: 2.72s\n",
            "241:\tlearn: 0.0663515\ttotal: 2.54s\tremaining: 2.7s\n",
            "242:\tlearn: 0.0659978\ttotal: 2.54s\tremaining: 2.69s\n",
            "243:\tlearn: 0.0657237\ttotal: 2.55s\tremaining: 2.67s\n",
            "244:\tlearn: 0.0653022\ttotal: 2.56s\tremaining: 2.66s\n",
            "245:\tlearn: 0.0649134\ttotal: 2.56s\tremaining: 2.64s\n",
            "246:\tlearn: 0.0647095\ttotal: 2.57s\tremaining: 2.63s\n",
            "247:\tlearn: 0.0644316\ttotal: 2.57s\tremaining: 2.62s\n",
            "248:\tlearn: 0.0640107\ttotal: 2.58s\tremaining: 2.6s\n",
            "249:\tlearn: 0.0638547\ttotal: 2.59s\tremaining: 2.59s\n",
            "250:\tlearn: 0.0635122\ttotal: 2.59s\tremaining: 2.57s\n",
            "251:\tlearn: 0.0632819\ttotal: 2.6s\tremaining: 2.56s\n",
            "252:\tlearn: 0.0629303\ttotal: 2.6s\tremaining: 2.54s\n",
            "253:\tlearn: 0.0626910\ttotal: 2.61s\tremaining: 2.53s\n",
            "254:\tlearn: 0.0623282\ttotal: 2.62s\tremaining: 2.52s\n",
            "255:\tlearn: 0.0619913\ttotal: 2.62s\tremaining: 2.5s\n",
            "256:\tlearn: 0.0616319\ttotal: 2.63s\tremaining: 2.49s\n",
            "257:\tlearn: 0.0615243\ttotal: 2.64s\tremaining: 2.47s\n",
            "258:\tlearn: 0.0613787\ttotal: 2.64s\tremaining: 2.46s\n",
            "259:\tlearn: 0.0610935\ttotal: 2.65s\tremaining: 2.45s\n",
            "260:\tlearn: 0.0607912\ttotal: 2.66s\tremaining: 2.43s\n",
            "261:\tlearn: 0.0605803\ttotal: 2.66s\tremaining: 2.42s\n",
            "262:\tlearn: 0.0601876\ttotal: 2.67s\tremaining: 2.4s\n",
            "263:\tlearn: 0.0598183\ttotal: 2.67s\tremaining: 2.39s\n",
            "264:\tlearn: 0.0594500\ttotal: 2.68s\tremaining: 2.38s\n",
            "265:\tlearn: 0.0591146\ttotal: 2.69s\tremaining: 2.37s\n",
            "266:\tlearn: 0.0588895\ttotal: 2.69s\tremaining: 2.35s\n",
            "267:\tlearn: 0.0585728\ttotal: 2.7s\tremaining: 2.34s\n",
            "268:\tlearn: 0.0580419\ttotal: 2.71s\tremaining: 2.33s\n",
            "269:\tlearn: 0.0578049\ttotal: 2.73s\tremaining: 2.33s\n",
            "270:\tlearn: 0.0575943\ttotal: 2.74s\tremaining: 2.32s\n",
            "271:\tlearn: 0.0572510\ttotal: 2.75s\tremaining: 2.31s\n",
            "272:\tlearn: 0.0570653\ttotal: 2.76s\tremaining: 2.29s\n",
            "273:\tlearn: 0.0567259\ttotal: 2.76s\tremaining: 2.28s\n",
            "274:\tlearn: 0.0564876\ttotal: 2.77s\tremaining: 2.27s\n",
            "275:\tlearn: 0.0562902\ttotal: 2.78s\tremaining: 2.25s\n",
            "276:\tlearn: 0.0561263\ttotal: 2.78s\tremaining: 2.24s\n",
            "277:\tlearn: 0.0559283\ttotal: 2.79s\tremaining: 2.23s\n",
            "278:\tlearn: 0.0557409\ttotal: 2.8s\tremaining: 2.22s\n",
            "279:\tlearn: 0.0555736\ttotal: 2.81s\tremaining: 2.2s\n",
            "280:\tlearn: 0.0552889\ttotal: 2.81s\tremaining: 2.19s\n",
            "281:\tlearn: 0.0548843\ttotal: 2.82s\tremaining: 2.18s\n",
            "282:\tlearn: 0.0547158\ttotal: 2.82s\tremaining: 2.17s\n",
            "283:\tlearn: 0.0545653\ttotal: 2.83s\tremaining: 2.15s\n",
            "284:\tlearn: 0.0543058\ttotal: 2.84s\tremaining: 2.14s\n",
            "285:\tlearn: 0.0539275\ttotal: 2.84s\tremaining: 2.13s\n",
            "286:\tlearn: 0.0537095\ttotal: 2.85s\tremaining: 2.12s\n",
            "287:\tlearn: 0.0535866\ttotal: 2.86s\tremaining: 2.1s\n",
            "288:\tlearn: 0.0535052\ttotal: 2.86s\tremaining: 2.09s\n",
            "289:\tlearn: 0.0533759\ttotal: 2.87s\tremaining: 2.08s\n",
            "290:\tlearn: 0.0532437\ttotal: 2.88s\tremaining: 2.06s\n",
            "291:\tlearn: 0.0529399\ttotal: 2.88s\tremaining: 2.05s\n",
            "292:\tlearn: 0.0527868\ttotal: 2.89s\tremaining: 2.04s\n",
            "293:\tlearn: 0.0526445\ttotal: 2.89s\tremaining: 2.03s\n",
            "294:\tlearn: 0.0524400\ttotal: 2.9s\tremaining: 2.02s\n",
            "295:\tlearn: 0.0521705\ttotal: 2.91s\tremaining: 2s\n",
            "296:\tlearn: 0.0519280\ttotal: 2.91s\tremaining: 1.99s\n",
            "297:\tlearn: 0.0517237\ttotal: 2.92s\tremaining: 1.98s\n",
            "298:\tlearn: 0.0514103\ttotal: 2.93s\tremaining: 1.97s\n",
            "299:\tlearn: 0.0510590\ttotal: 2.93s\tremaining: 1.96s\n",
            "300:\tlearn: 0.0509279\ttotal: 2.94s\tremaining: 1.94s\n",
            "301:\tlearn: 0.0507386\ttotal: 2.95s\tremaining: 1.93s\n",
            "302:\tlearn: 0.0505758\ttotal: 2.95s\tremaining: 1.92s\n",
            "303:\tlearn: 0.0504202\ttotal: 2.96s\tremaining: 1.91s\n",
            "304:\tlearn: 0.0501727\ttotal: 2.97s\tremaining: 1.9s\n",
            "305:\tlearn: 0.0500655\ttotal: 2.97s\tremaining: 1.88s\n",
            "306:\tlearn: 0.0498470\ttotal: 2.98s\tremaining: 1.87s\n",
            "307:\tlearn: 0.0495457\ttotal: 2.99s\tremaining: 1.86s\n",
            "308:\tlearn: 0.0493913\ttotal: 3s\tremaining: 1.85s\n",
            "309:\tlearn: 0.0491799\ttotal: 3.01s\tremaining: 1.84s\n",
            "310:\tlearn: 0.0490082\ttotal: 3.01s\tremaining: 1.83s\n",
            "311:\tlearn: 0.0488801\ttotal: 3.02s\tremaining: 1.82s\n",
            "312:\tlearn: 0.0486319\ttotal: 3.04s\tremaining: 1.81s\n",
            "313:\tlearn: 0.0482591\ttotal: 3.05s\tremaining: 1.8s\n",
            "314:\tlearn: 0.0481018\ttotal: 3.05s\tremaining: 1.79s\n",
            "315:\tlearn: 0.0478934\ttotal: 3.06s\tremaining: 1.78s\n",
            "316:\tlearn: 0.0477264\ttotal: 3.07s\tremaining: 1.77s\n",
            "317:\tlearn: 0.0474585\ttotal: 3.07s\tremaining: 1.76s\n",
            "318:\tlearn: 0.0472444\ttotal: 3.08s\tremaining: 1.75s\n",
            "319:\tlearn: 0.0470961\ttotal: 3.09s\tremaining: 1.74s\n",
            "320:\tlearn: 0.0467692\ttotal: 3.09s\tremaining: 1.72s\n",
            "321:\tlearn: 0.0465882\ttotal: 3.1s\tremaining: 1.71s\n",
            "322:\tlearn: 0.0465152\ttotal: 3.11s\tremaining: 1.7s\n",
            "323:\tlearn: 0.0463693\ttotal: 3.11s\tremaining: 1.69s\n",
            "324:\tlearn: 0.0461828\ttotal: 3.12s\tremaining: 1.68s\n",
            "325:\tlearn: 0.0459484\ttotal: 3.13s\tremaining: 1.67s\n",
            "326:\tlearn: 0.0457986\ttotal: 3.14s\tremaining: 1.66s\n",
            "327:\tlearn: 0.0456067\ttotal: 3.15s\tremaining: 1.65s\n",
            "328:\tlearn: 0.0453347\ttotal: 3.15s\tremaining: 1.64s\n",
            "329:\tlearn: 0.0452278\ttotal: 3.16s\tremaining: 1.63s\n",
            "330:\tlearn: 0.0449958\ttotal: 3.17s\tremaining: 1.62s\n",
            "331:\tlearn: 0.0448255\ttotal: 3.17s\tremaining: 1.6s\n",
            "332:\tlearn: 0.0447085\ttotal: 3.18s\tremaining: 1.59s\n",
            "333:\tlearn: 0.0445313\ttotal: 3.19s\tremaining: 1.58s\n",
            "334:\tlearn: 0.0443283\ttotal: 3.19s\tremaining: 1.57s\n",
            "335:\tlearn: 0.0442230\ttotal: 3.2s\tremaining: 1.56s\n",
            "336:\tlearn: 0.0441170\ttotal: 3.21s\tremaining: 1.55s\n",
            "337:\tlearn: 0.0439194\ttotal: 3.21s\tremaining: 1.54s\n",
            "338:\tlearn: 0.0438046\ttotal: 3.22s\tremaining: 1.53s\n",
            "339:\tlearn: 0.0435686\ttotal: 3.23s\tremaining: 1.52s\n",
            "340:\tlearn: 0.0433317\ttotal: 3.23s\tremaining: 1.51s\n",
            "341:\tlearn: 0.0431757\ttotal: 3.24s\tremaining: 1.5s\n",
            "342:\tlearn: 0.0429858\ttotal: 3.25s\tremaining: 1.49s\n",
            "343:\tlearn: 0.0428574\ttotal: 3.25s\tremaining: 1.48s\n",
            "344:\tlearn: 0.0426288\ttotal: 3.26s\tremaining: 1.46s\n",
            "345:\tlearn: 0.0425357\ttotal: 3.27s\tremaining: 1.45s\n",
            "346:\tlearn: 0.0424468\ttotal: 3.27s\tremaining: 1.44s\n",
            "347:\tlearn: 0.0423578\ttotal: 3.28s\tremaining: 1.43s\n",
            "348:\tlearn: 0.0419963\ttotal: 3.29s\tremaining: 1.42s\n",
            "349:\tlearn: 0.0419216\ttotal: 3.29s\tremaining: 1.41s\n",
            "350:\tlearn: 0.0417783\ttotal: 3.3s\tremaining: 1.4s\n",
            "351:\tlearn: 0.0416029\ttotal: 3.31s\tremaining: 1.39s\n",
            "352:\tlearn: 0.0414927\ttotal: 3.31s\tremaining: 1.38s\n",
            "353:\tlearn: 0.0413607\ttotal: 3.32s\tremaining: 1.37s\n",
            "354:\tlearn: 0.0411384\ttotal: 3.33s\tremaining: 1.36s\n",
            "355:\tlearn: 0.0410582\ttotal: 3.34s\tremaining: 1.35s\n",
            "356:\tlearn: 0.0408824\ttotal: 3.35s\tremaining: 1.34s\n",
            "357:\tlearn: 0.0407832\ttotal: 3.35s\tremaining: 1.33s\n",
            "358:\tlearn: 0.0406251\ttotal: 3.36s\tremaining: 1.32s\n",
            "359:\tlearn: 0.0404441\ttotal: 3.37s\tremaining: 1.31s\n",
            "360:\tlearn: 0.0403544\ttotal: 3.37s\tremaining: 1.3s\n",
            "361:\tlearn: 0.0402443\ttotal: 3.38s\tremaining: 1.29s\n",
            "362:\tlearn: 0.0400855\ttotal: 3.38s\tremaining: 1.28s\n",
            "363:\tlearn: 0.0397941\ttotal: 3.39s\tremaining: 1.27s\n",
            "364:\tlearn: 0.0397382\ttotal: 3.4s\tremaining: 1.26s\n",
            "365:\tlearn: 0.0395809\ttotal: 3.4s\tremaining: 1.25s\n",
            "366:\tlearn: 0.0395161\ttotal: 3.41s\tremaining: 1.24s\n",
            "367:\tlearn: 0.0393798\ttotal: 3.42s\tremaining: 1.23s\n",
            "368:\tlearn: 0.0392467\ttotal: 3.42s\tremaining: 1.22s\n",
            "369:\tlearn: 0.0391177\ttotal: 3.43s\tremaining: 1.2s\n",
            "370:\tlearn: 0.0390246\ttotal: 3.44s\tremaining: 1.19s\n",
            "371:\tlearn: 0.0389000\ttotal: 3.44s\tremaining: 1.18s\n",
            "372:\tlearn: 0.0387549\ttotal: 3.45s\tremaining: 1.17s\n",
            "373:\tlearn: 0.0386460\ttotal: 3.45s\tremaining: 1.16s\n",
            "374:\tlearn: 0.0385109\ttotal: 3.46s\tremaining: 1.15s\n",
            "375:\tlearn: 0.0384781\ttotal: 3.47s\tremaining: 1.14s\n",
            "376:\tlearn: 0.0384136\ttotal: 3.47s\tremaining: 1.13s\n",
            "377:\tlearn: 0.0382619\ttotal: 3.48s\tremaining: 1.12s\n",
            "378:\tlearn: 0.0381567\ttotal: 3.48s\tremaining: 1.11s\n",
            "379:\tlearn: 0.0380574\ttotal: 3.49s\tremaining: 1.1s\n",
            "380:\tlearn: 0.0379903\ttotal: 3.5s\tremaining: 1.09s\n",
            "381:\tlearn: 0.0378066\ttotal: 3.5s\tremaining: 1.08s\n",
            "382:\tlearn: 0.0377125\ttotal: 3.51s\tremaining: 1.07s\n",
            "383:\tlearn: 0.0376308\ttotal: 3.56s\tremaining: 1.07s\n",
            "384:\tlearn: 0.0375243\ttotal: 3.61s\tremaining: 1.08s\n",
            "385:\tlearn: 0.0374227\ttotal: 3.64s\tremaining: 1.07s\n",
            "386:\tlearn: 0.0372968\ttotal: 3.69s\tremaining: 1.08s\n",
            "387:\tlearn: 0.0371362\ttotal: 3.73s\tremaining: 1.08s\n",
            "388:\tlearn: 0.0370046\ttotal: 3.77s\tremaining: 1.07s\n",
            "389:\tlearn: 0.0367936\ttotal: 3.77s\tremaining: 1.06s\n",
            "390:\tlearn: 0.0366540\ttotal: 3.78s\tremaining: 1.05s\n",
            "391:\tlearn: 0.0364835\ttotal: 3.81s\tremaining: 1.05s\n",
            "392:\tlearn: 0.0364150\ttotal: 3.82s\tremaining: 1.04s\n",
            "393:\tlearn: 0.0361982\ttotal: 3.82s\tremaining: 1.03s\n",
            "394:\tlearn: 0.0361112\ttotal: 3.84s\tremaining: 1.02s\n",
            "395:\tlearn: 0.0360009\ttotal: 3.85s\tremaining: 1.01s\n",
            "396:\tlearn: 0.0359013\ttotal: 3.86s\tremaining: 1s\n",
            "397:\tlearn: 0.0358125\ttotal: 3.87s\tremaining: 991ms\n",
            "398:\tlearn: 0.0357231\ttotal: 3.88s\tremaining: 982ms\n",
            "399:\tlearn: 0.0355676\ttotal: 3.89s\tremaining: 972ms\n",
            "400:\tlearn: 0.0354506\ttotal: 3.9s\tremaining: 963ms\n",
            "401:\tlearn: 0.0353234\ttotal: 3.91s\tremaining: 953ms\n",
            "402:\tlearn: 0.0352239\ttotal: 3.92s\tremaining: 944ms\n",
            "403:\tlearn: 0.0350990\ttotal: 3.94s\tremaining: 935ms\n",
            "404:\tlearn: 0.0349956\ttotal: 3.94s\tremaining: 925ms\n",
            "405:\tlearn: 0.0347456\ttotal: 3.95s\tremaining: 915ms\n",
            "406:\tlearn: 0.0346292\ttotal: 3.97s\tremaining: 908ms\n",
            "407:\tlearn: 0.0345048\ttotal: 3.99s\tremaining: 900ms\n",
            "408:\tlearn: 0.0343720\ttotal: 4s\tremaining: 891ms\n",
            "409:\tlearn: 0.0342371\ttotal: 4.01s\tremaining: 881ms\n",
            "410:\tlearn: 0.0341220\ttotal: 4.03s\tremaining: 872ms\n",
            "411:\tlearn: 0.0339942\ttotal: 4.06s\tremaining: 868ms\n",
            "412:\tlearn: 0.0338981\ttotal: 4.08s\tremaining: 859ms\n",
            "413:\tlearn: 0.0337956\ttotal: 4.09s\tremaining: 850ms\n",
            "414:\tlearn: 0.0337087\ttotal: 4.12s\tremaining: 844ms\n",
            "415:\tlearn: 0.0336105\ttotal: 4.13s\tremaining: 834ms\n",
            "416:\tlearn: 0.0334717\ttotal: 4.14s\tremaining: 824ms\n",
            "417:\tlearn: 0.0333403\ttotal: 4.15s\tremaining: 814ms\n",
            "418:\tlearn: 0.0332893\ttotal: 4.16s\tremaining: 804ms\n",
            "419:\tlearn: 0.0331839\ttotal: 4.18s\tremaining: 796ms\n",
            "420:\tlearn: 0.0329190\ttotal: 4.18s\tremaining: 785ms\n",
            "421:\tlearn: 0.0328299\ttotal: 4.21s\tremaining: 779ms\n",
            "422:\tlearn: 0.0327565\ttotal: 4.23s\tremaining: 769ms\n",
            "423:\tlearn: 0.0327088\ttotal: 4.23s\tremaining: 759ms\n",
            "424:\tlearn: 0.0326612\ttotal: 4.24s\tremaining: 749ms\n",
            "425:\tlearn: 0.0326190\ttotal: 4.25s\tremaining: 739ms\n",
            "426:\tlearn: 0.0325373\ttotal: 4.27s\tremaining: 730ms\n",
            "427:\tlearn: 0.0324813\ttotal: 4.28s\tremaining: 720ms\n",
            "428:\tlearn: 0.0323260\ttotal: 4.29s\tremaining: 710ms\n",
            "429:\tlearn: 0.0322470\ttotal: 4.31s\tremaining: 702ms\n",
            "430:\tlearn: 0.0321843\ttotal: 4.32s\tremaining: 691ms\n",
            "431:\tlearn: 0.0320411\ttotal: 4.33s\tremaining: 681ms\n",
            "432:\tlearn: 0.0319219\ttotal: 4.36s\tremaining: 674ms\n",
            "433:\tlearn: 0.0318169\ttotal: 4.39s\tremaining: 668ms\n",
            "434:\tlearn: 0.0316848\ttotal: 4.42s\tremaining: 661ms\n",
            "435:\tlearn: 0.0316288\ttotal: 4.46s\tremaining: 654ms\n",
            "436:\tlearn: 0.0315251\ttotal: 4.49s\tremaining: 648ms\n",
            "437:\tlearn: 0.0314364\ttotal: 4.53s\tremaining: 641ms\n",
            "438:\tlearn: 0.0313463\ttotal: 4.56s\tremaining: 634ms\n",
            "439:\tlearn: 0.0312368\ttotal: 4.6s\tremaining: 627ms\n",
            "440:\tlearn: 0.0311883\ttotal: 4.63s\tremaining: 620ms\n",
            "441:\tlearn: 0.0310411\ttotal: 4.67s\tremaining: 613ms\n",
            "442:\tlearn: 0.0309538\ttotal: 4.71s\tremaining: 606ms\n",
            "443:\tlearn: 0.0308063\ttotal: 4.75s\tremaining: 599ms\n",
            "444:\tlearn: 0.0307463\ttotal: 4.76s\tremaining: 588ms\n",
            "445:\tlearn: 0.0306321\ttotal: 4.77s\tremaining: 578ms\n",
            "446:\tlearn: 0.0305609\ttotal: 4.79s\tremaining: 567ms\n",
            "447:\tlearn: 0.0305115\ttotal: 4.8s\tremaining: 558ms\n",
            "448:\tlearn: 0.0304207\ttotal: 4.81s\tremaining: 547ms\n",
            "449:\tlearn: 0.0303868\ttotal: 4.83s\tremaining: 536ms\n",
            "450:\tlearn: 0.0302555\ttotal: 4.83s\tremaining: 525ms\n",
            "451:\tlearn: 0.0301740\ttotal: 4.87s\tremaining: 517ms\n",
            "452:\tlearn: 0.0300421\ttotal: 4.88s\tremaining: 506ms\n",
            "453:\tlearn: 0.0299346\ttotal: 4.9s\tremaining: 496ms\n",
            "454:\tlearn: 0.0298860\ttotal: 4.91s\tremaining: 485ms\n",
            "455:\tlearn: 0.0297780\ttotal: 4.92s\tremaining: 475ms\n",
            "456:\tlearn: 0.0297377\ttotal: 4.93s\tremaining: 464ms\n",
            "457:\tlearn: 0.0296762\ttotal: 4.96s\tremaining: 455ms\n",
            "458:\tlearn: 0.0295866\ttotal: 4.97s\tremaining: 444ms\n",
            "459:\tlearn: 0.0295151\ttotal: 4.98s\tremaining: 433ms\n",
            "460:\tlearn: 0.0294296\ttotal: 5.01s\tremaining: 424ms\n",
            "461:\tlearn: 0.0293562\ttotal: 5.02s\tremaining: 413ms\n",
            "462:\tlearn: 0.0292615\ttotal: 5.04s\tremaining: 402ms\n",
            "463:\tlearn: 0.0291041\ttotal: 5.06s\tremaining: 392ms\n",
            "464:\tlearn: 0.0290125\ttotal: 5.08s\tremaining: 382ms\n",
            "465:\tlearn: 0.0288886\ttotal: 5.09s\tremaining: 372ms\n",
            "466:\tlearn: 0.0288353\ttotal: 5.13s\tremaining: 362ms\n",
            "467:\tlearn: 0.0287561\ttotal: 5.13s\tremaining: 351ms\n",
            "468:\tlearn: 0.0287149\ttotal: 5.15s\tremaining: 340ms\n",
            "469:\tlearn: 0.0285858\ttotal: 5.17s\tremaining: 330ms\n",
            "470:\tlearn: 0.0285205\ttotal: 5.18s\tremaining: 319ms\n",
            "471:\tlearn: 0.0284149\ttotal: 5.2s\tremaining: 308ms\n",
            "472:\tlearn: 0.0283439\ttotal: 5.2s\tremaining: 297ms\n",
            "473:\tlearn: 0.0282514\ttotal: 5.22s\tremaining: 286ms\n",
            "474:\tlearn: 0.0281490\ttotal: 5.24s\tremaining: 276ms\n",
            "475:\tlearn: 0.0280145\ttotal: 5.25s\tremaining: 265ms\n",
            "476:\tlearn: 0.0279449\ttotal: 5.26s\tremaining: 254ms\n",
            "477:\tlearn: 0.0278963\ttotal: 5.28s\tremaining: 243ms\n",
            "478:\tlearn: 0.0278023\ttotal: 5.29s\tremaining: 232ms\n",
            "479:\tlearn: 0.0277547\ttotal: 5.3s\tremaining: 221ms\n",
            "480:\tlearn: 0.0276893\ttotal: 5.32s\tremaining: 210ms\n",
            "481:\tlearn: 0.0276672\ttotal: 5.36s\tremaining: 200ms\n",
            "482:\tlearn: 0.0276117\ttotal: 5.38s\tremaining: 189ms\n",
            "483:\tlearn: 0.0275357\ttotal: 5.44s\tremaining: 180ms\n",
            "484:\tlearn: 0.0274421\ttotal: 5.45s\tremaining: 169ms\n",
            "485:\tlearn: 0.0273813\ttotal: 5.47s\tremaining: 157ms\n",
            "486:\tlearn: 0.0273159\ttotal: 5.49s\tremaining: 146ms\n",
            "487:\tlearn: 0.0272314\ttotal: 5.5s\tremaining: 135ms\n",
            "488:\tlearn: 0.0271648\ttotal: 5.51s\tremaining: 124ms\n",
            "489:\tlearn: 0.0271226\ttotal: 5.52s\tremaining: 113ms\n",
            "490:\tlearn: 0.0270507\ttotal: 5.55s\tremaining: 102ms\n",
            "491:\tlearn: 0.0269433\ttotal: 5.59s\tremaining: 90.9ms\n",
            "492:\tlearn: 0.0268858\ttotal: 5.63s\tremaining: 79.9ms\n",
            "493:\tlearn: 0.0268267\ttotal: 5.66s\tremaining: 68.8ms\n",
            "494:\tlearn: 0.0267714\ttotal: 5.72s\tremaining: 57.8ms\n",
            "495:\tlearn: 0.0267205\ttotal: 5.76s\tremaining: 46.5ms\n",
            "496:\tlearn: 0.0265883\ttotal: 5.79s\tremaining: 35ms\n",
            "497:\tlearn: 0.0264951\ttotal: 5.82s\tremaining: 23.4ms\n",
            "498:\tlearn: 0.0264360\ttotal: 5.85s\tremaining: 11.7ms\n",
            "499:\tlearn: 0.0263474\ttotal: 5.87s\tremaining: 0us\n",
            "Accuracy: 67.5676\n",
            "Mean Absolute Error: 0.405\n",
            "F1 Score: 66.4296\n",
            "AUC: 0.877\n",
            "Confusion Matrix : \n",
            " [[15  5  1]\n",
            " [ 0  9  1]\n",
            " [ 2  3  1]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}